{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from data_helper import XY_from_df\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from bincls import BinaryClassificationAverageReport\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# sklearn ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 5\n",
    "FOLD = 10\n",
    "TRAIN_PATH = \"../dataset/train.csv\"\n",
    "TARGET_NAMES = [\"bad\", \"good\"]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "X, Y = XY_from_df(df_train)\n",
    "\n",
    "stratified_folder = StratifiedKFold(n_splits=FOLD, random_state=SEED, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args tunning ( RandomForestClassifier )\n",
    "\n",
    "### Decision Tree\n",
    "- max_features :選擇最適屬性時劃分的特徵不能超過此值。 當為整數時，即最大特徵數；當為小數時，訓練集特徵數*小數；\n",
    "- max_depth : (default=None)設置樹的最大深度，默認為None，這樣建樹時，會使每一個葉節點只有一個類別，或是達到min_samples_split。\n",
    "- min_samples_split :根據屬性劃分節點時，每個劃分最少的樣本數。\n",
    "- min_samples_leaf :葉子節點最少的樣本數。\n",
    "- max_leaf_nodes : (default=None)葉子樹的最大樣本數。\n",
    "- min_weight_fraction_leaf : (default=0)葉子節點所需要的最小權值。\n",
    "\n",
    "### Random Forest\n",
    "- n_estimators =10：決策樹的個數，越多越好，但是性能就會越差，至少100左右，可以達到可接受的性能和誤差率。 \n",
    "- bootstrap =True ：是否有放回的採樣。  \n",
    "- oob_score=False：oob（out of band，帶外）數據，即：在某次決策樹訓練中沒有被bootstrap選中的數據。多單個模型的參數訓練，我們知道可以用cross validation（cv）來進行，但是特別消耗時間，而且對於隨機森林這種情況也沒有大的必要，所以就用這個數據對決策樹模型進行驗證，算是一個簡單的交叉驗證。性能消耗小，但是效果不錯。  \n",
    "- n_jobs=1：並行job個數。這個在ensemble算法中非常重要，尤其是bagging（而非boosting，因為boosting的每次迭代之間有影響，所以很難進行並行化），因為可以並行從而提高性能。1=不並行；n：n個並行；-1：CPU有多少core，就啟動多少job\n",
    "- warm_start=False：熱啟動，決定是否使用上次調用該類的結果然後增加新的。  \n",
    "- class_weight=None：各個label的權重。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valid_process(stratified_folder, X, Y, model, report, mode=\"report\", up=False):\n",
    "    \n",
    "    def upsampling(X,Y,train_index):\n",
    "        pos = []\n",
    "        for i, t in enumerate(Y[train_index]):\n",
    "            if t == 0: pos.append(i)\n",
    "        X_new = np.append(X[train_index], X[pos], axis=0)\n",
    "        Y_new = np.append(Y[train_index], Y[pos], axis=0)\n",
    "        idxs = [i for i in range(len(Y_new))]\n",
    "        idxs = shuffle(idxs, random_state=3)\n",
    "        return X_new[idxs], Y_new[idxs]\n",
    "    \n",
    "    for train_index, valid_index in stratified_folder.split(X, Y):\n",
    "        if up:\n",
    "            X_train ,Y_train = upsampling(X,Y,train_index)\n",
    "        else:\n",
    "            X_train ,Y_train = X[train_index], Y[train_index]\n",
    "        if mode == \"report\": print(\".\", end=\" \")\n",
    "        m = model\n",
    "        m.fit(X_train, Y_train)\n",
    "        Y_valid_pred = m.predict(X[valid_index])\n",
    "        cm = confusion_matrix(Y[valid_index], Y_valid_pred)\n",
    "        report.cm_append(cm)\n",
    "    if mode == \"report\":\n",
    "        report.avg_cm_report()\n",
    "        return None\n",
    "    if mode == \"obj\":\n",
    "        return report.object_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Combination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 10 {0: 2.0} True\n",
      "0.2 10 {0: 2.0} False\n",
      "0.2 10 {0: 5.0} True\n",
      "0.2 10 {0: 5.0} False\n",
      "0.2 10 {0: 10.0} True\n",
      "0.2 10 {0: 10.0} False\n",
      "0.2 20 {0: 2.0} True\n",
      "0.2 20 {0: 2.0} False\n",
      "0.2 20 {0: 5.0} True\n",
      "0.2 20 {0: 5.0} False\n",
      "0.2 20 {0: 10.0} True\n",
      "0.2 20 {0: 10.0} False\n",
      "0.5 10 {0: 2.0} True\n",
      "0.5 10 {0: 2.0} False\n",
      "0.5 10 {0: 5.0} True\n",
      "0.5 10 {0: 5.0} False\n",
      "0.5 10 {0: 10.0} True\n",
      "0.5 10 {0: 10.0} False\n",
      "0.5 20 {0: 2.0} True\n",
      "0.5 20 {0: 2.0} False\n",
      "0.5 20 {0: 5.0} True\n",
      "0.5 20 {0: 5.0} False\n",
      "0.5 20 {0: 10.0} True\n",
      "0.5 20 {0: 10.0} False\n",
      "1.0 10 {0: 2.0} True\n",
      "1.0 10 {0: 2.0} False\n",
      "1.0 10 {0: 5.0} True\n",
      "1.0 10 {0: 5.0} False\n",
      "1.0 10 {0: 10.0} True\n",
      "1.0 10 {0: 10.0} False\n",
      "1.0 20 {0: 2.0} True\n",
      "1.0 20 {0: 2.0} False\n",
      "1.0 20 {0: 5.0} True\n",
      "1.0 20 {0: 5.0} False\n",
      "1.0 20 {0: 10.0} True\n",
      "1.0 20 {0: 10.0} False\n"
     ]
    }
   ],
   "source": [
    "max_obj_score = 0\n",
    "candidates = []\n",
    "\n",
    "max_features = [0.2, 0.5, 1.]\n",
    "min_samples_leaf = [10, 20]\n",
    "class_weight =[{0:2.}, {0:5.}, {0:10.}]\n",
    "\n",
    "for mf in max_features:\n",
    "    for msl in min_samples_leaf:\n",
    "        for cw in class_weight:\n",
    "            for up in [True, False]:\n",
    "                print(mf, msl, cw, up)\n",
    "                report = BinaryClassificationAverageReport(TARGET_NAMES)\n",
    "                rf = RandomForestClassifier(n_estimators = 500, max_features=mf, bootstrap =True, oob_score=True, n_jobs=3,\\\n",
    "                                            min_samples_leaf=msl, random_state=SEED, class_weight=cw)\n",
    "                obj_score = cross_valid_process(stratified_folder, X, Y, rf, report, mode=\"obj\", up=up)\n",
    "                if obj_score >= max_obj_score:\n",
    "                    candidates.append((mf, msl, cw, up, obj_score))\n",
    "                    max_obj_score = obj_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2, 10, {0: 2.0}, True, 0.7361493398639518),\n",
       " (0.2, 10, {0: 5.0}, True, 0.7943834391153833),\n",
       " (0.5, 10, {0: 5.0}, True, 0.7951712604045212)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness and Performance Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "\n",
      "Below number are the average of 10 fold.\n",
      "\n",
      "bad\n",
      "             precision:    46.99%\n",
      "                recall:    87.67%\n",
      "                    F1:    61.02%\n",
      "good\n",
      "             precision:    91.70%\n",
      "                recall:    57.00%\n",
      "                    F1:    69.98%\n",
      "---------------------------------\n",
      "             weight_F1:    67.29%\n",
      "                   acc:    66.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mf = 0.5\n",
    "msl = 10\n",
    "cw = {0: 5.0}\n",
    "\n",
    "report = BinaryClassificationAverageReport(TARGET_NAMES)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 500, max_features=mf, bootstrap =True, oob_score=True, n_jobs=3,\\\n",
    "                                        min_samples_leaf=msl, random_state=SEED, class_weight=cw)\n",
    "\n",
    "cross_valid_process(stratified_folder, X, Y, rf, report, \"report\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={0: 5.0},\n",
       "                       criterion='gini', max_depth=None, max_features=0.5,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=3,\n",
       "                       oob_score=True, random_state=5, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = 0.5\n",
    "msl = 10\n",
    "cw = {0: 5.0}\n",
    "\n",
    "def upsampling(X,Y):\n",
    "    pos = []\n",
    "    for i, t in enumerate(Y):\n",
    "        if t == 0: pos.append(i)\n",
    "    X_new = np.append(X, X[pos], axis=0)\n",
    "    Y_new = np.append(Y, Y[pos], axis=0)\n",
    "    idxs = [i for i in range(len(Y_new))]\n",
    "    idxs = shuffle(idxs, random_state=3)\n",
    "    return X_new[idxs], Y_new[idxs]\n",
    "\n",
    "X_new, Y_new = upsampling(X,Y)\n",
    "\n",
    "final_rf = RandomForestClassifier(n_estimators = 500, max_features=mf, bootstrap =True, oob_score=True, n_jobs=3,\\\n",
    "                                        min_samples_leaf=msl, random_state=SEED, class_weight=cw)\n",
    "final_rf.fit(X_new, Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_name = 'best_mdoel.pickle'\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    pickle.dump(final_rf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
