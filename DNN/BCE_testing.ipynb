{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Cross Entropy Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=None, logits=None, name=None\n",
    ")\n",
    "```\n",
    "\n",
    "以上的func是因為式子是將數值經過 sigmoid 變成機率值，再進 BCE 得到 loss，\n",
    "而這 func 的輸入為 logits，也就是不用再自己轉一層 sigmoid。\n",
    "\n",
    "當我們 tf.keras.losses.BinaryCrossentropy 設 from_logits = True 時\n",
    "會直接進 tf.nn.sigmoid_cross_entropy_with_logits。\n",
    "\n",
    "而設為 False 時，則會將經 sigmoid 值反向變回 logits，最終再進\n",
    "\n",
    "tf.nn.sigmoid_cross_entropy_with_logits，脫褲子放屁！\n",
    "\n",
    "```\n",
    "_epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n",
    "        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "        output = tf.log(output / (1 - output))\n",
    "```\n",
    "\n",
    "因此建議 tf.keras.losses.BinaryCrossentropy 直接用 from_logits = True\n",
    "且，tf.nn.sigmoid_cross_entropy_with_logits 是 numeric stable，原因為以下：\n",
    "\n",
    "```\n",
    "z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x)) 這個是 BCE 公式\n",
    "以下是化簡\n",
    "= z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n",
    "= z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n",
    "= z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n",
    "= (1 - z) * x + log(1 + exp(-x))\n",
    "= x - x * z + log(1 + exp(-x))\n",
    "```\n",
    "\n",
    "For x < 0, to avoid overflow in exp(-x), we reformulate the above， 會做以下事：\n",
    "\n",
    "```\n",
    " x - x * z + log(1 + exp(-x))\n",
    "= log(exp(x)) - x * z + log(1 + exp(-x))\n",
    "= - x * z + log(1 + exp(x))\n",
    "```\n",
    "\n",
    "```\n",
    "max(x, 0) - x * z + log(1 + exp(-abs(x)))\n",
    "```\n",
    "由以下實驗可以看到，math.exp x給太大會 overflow，所以再轉成下面那\n",
    "```\n",
    "import math\n",
    "\n",
    "def a(x, z):\n",
    "    return -x*z + math.log(1+math.exp(x))\n",
    "\n",
    "def b(x, z):\n",
    "    return max(x,0) - x*z +math.log(1+math.exp(-abs(x)))\n",
    "\n",
    "print(a(1000,5))\n",
    "# print(b(1000000,5))\n",
    "```\n",
    "再來若要知道機率值，可以 predict 出來的值再自己做 sigmoid 即可 \n",
    "會壓在 0~1 之間，極大接近 1 ，極小接近 0\n",
    "\n",
    "出來的便可當作是 label 1 的機率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import my_trace as tc\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from data_helper import XY_from_df\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# tensorflow only show Error\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# sklearn ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 5\n",
    "TRAIN_PATH = \"../dataset/train.csv\"\n",
    "TARGET_NAMES = [\"bad\", \"good\"]\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# get data\n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "X, Y = XY_from_df(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Struture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        \n",
    "    tf.keras.layers.Dense(64, activation=None),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.5, seed=SEED),\n",
    "        \n",
    "    tf.keras.layers.Dense(32, activation=None),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.5, seed=SEED),\n",
    "        \n",
    "    tf.keras.layers.Dense(1,activation=None),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005,name='adam'),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fde3429c990>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X, Y, epochs=100, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.66855  ],\n",
       "       [ 4.721215 ],\n",
       "       [-6.414172 ],\n",
       "       [-0.9882879],\n",
       "       [-5.2085776],\n",
       "       [ 9.643806 ],\n",
       "       [ 3.7633142],\n",
       "       [ 3.3025436],\n",
       "       [24.281986 ],\n",
       "       [-3.9070172]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到 output 機率\n",
    "def predict_proba(X):\n",
    "    results = []\n",
    "    P = tf.nn.sigmoid(model.predict(X))\n",
    "    for p in P.numpy():\n",
    "        label_1_p = float(p[0])\n",
    "        results.append([1-label_1_p , label_1_p])\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.33001328e-05, 9.99936700e-01],\n",
       "       [8.82577896e-03, 9.91174221e-01],\n",
       "       [9.98364504e-01, 1.63549639e-03],\n",
       "       [7.28749633e-01, 2.71250367e-01],\n",
       "       [9.94560305e-01, 5.43969544e-03],\n",
       "       [6.48498535e-05, 9.99935150e-01],\n",
       "       [2.26804018e-02, 9.77319598e-01],\n",
       "       [3.54839563e-02, 9.64516044e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [9.80295699e-01, 1.97043009e-02]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba(X[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
