{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from data_helper import XY_from_df\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from bincls import BinaryClassificationAverageReport\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# sklearn ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 5\n",
    "FOLD = 10\n",
    "TRAIN_PATH = \"../dataset/train.csv\"\n",
    "TARGET_NAMES = [\"bad\", \"good\"]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "X, Y = XY_from_df(df_train)\n",
    "\n",
    "stratified_folder = StratifiedKFold(n_splits=FOLD, random_state=SEED, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args tunning ( RandomForestClassifier )\n",
    "### Decision Tree\n",
    "- max_features :選擇最適屬性時劃分的特徵不能超過此值。 當為整數時，即最大特徵數；當為小數時，訓練集特徵數*小數；\n",
    "- max_depth : (default=None)設置樹的最大深度，默認為None，這樣建樹時，會使每一個葉節點只有一個類別，或是達到min_samples_split。\n",
    "- min_samples_split :根據屬性劃分節點時，每個劃分最少的樣本數。\n",
    "- min_samples_leaf :葉子節點最少的樣本數。\n",
    "- max_leaf_nodes : (default=None)葉子樹的最大樣本數。\n",
    "- min_weight_fraction_leaf : (default=0)葉子節點所需要的最小權值。\n",
    "\n",
    "### Adaboost\n",
    "- base_estimator:基分類器，默認是決策樹，在該分類器基礎上進行boosting，理論上可以是任意一個分類器，但是如果是其他分類器時需要指明樣本權重。\n",
    "- n_estimators:基分類器提升（循環）次數，默認是50次，這個值過大，模型容易過擬合；值過小，模型容易欠擬合。\n",
    "- learning_rate:學習率，表示梯度收斂速度，默認為1，如果過大，容易錯過最優值，如果過小，則收斂速度會很慢；該值需要和n_estimators進行一個權衡，當分類器迭代次數較少時，學習率可以小一些，當迭代次數較多時，學習率可以適當放大。\n",
    "- algorithm:boosting算法，也就是模型提升準則，有兩種方式SAMME, 和SAMME.R兩種，默認是SAMME.R，兩者的區別主要是弱學習器權重的度量，前者是對樣本集預測錯誤的概率進行劃分的，後者是對樣本集的預測錯誤的比例，即錯分率進行劃分的，默認是用的SAMME.R。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valid_process(stratified_folder, X, Y, model, report, mode=\"report\", up=False):\n",
    "    \n",
    "    def upsampling(X,Y,train_index):\n",
    "        pos = []\n",
    "        for i, t in enumerate(Y[train_index]):\n",
    "            if t == 0: pos.append(i)\n",
    "        X_new = np.append(X[train_index], X[pos], axis=0)\n",
    "        Y_new = np.append(Y[train_index], Y[pos], axis=0)\n",
    "        idxs = [i for i in range(len(Y_new))]\n",
    "        idxs = shuffle(idxs, random_state=3)\n",
    "        return X_new[idxs], Y_new[idxs]\n",
    "    \n",
    "    for train_index, valid_index in stratified_folder.split(X, Y):\n",
    "        if up:\n",
    "            X_train ,Y_train = upsampling(X,Y,train_index)\n",
    "        else:\n",
    "            X_train ,Y_train = X[train_index], Y[train_index]\n",
    "        if mode == \"report\": print(\".\", end=\" \")\n",
    "        m = model\n",
    "        m.fit(X_train, Y_train)\n",
    "        Y_valid_pred = m.predict(X[valid_index])\n",
    "        cm = confusion_matrix(Y[valid_index], Y_valid_pred)\n",
    "        report.cm_append(cm)\n",
    "    if mode == \"report\":\n",
    "        report.avg_cm_report()\n",
    "        return None\n",
    "    if mode == \"obj\":\n",
    "        return report.object_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 10 SAMME.R True\n",
      "1 4 10 SAMME.R False\n",
      "1 4 10 SAMME True\n",
      "1 4 10 SAMME False\n",
      "1 4 15 SAMME.R True\n",
      "1 4 15 SAMME.R False\n",
      "1 4 15 SAMME True\n",
      "1 4 15 SAMME False\n",
      "1 4 20 SAMME.R True\n",
      "1 4 20 SAMME.R False\n",
      "1 4 20 SAMME True\n",
      "1 4 20 SAMME False\n",
      "1 5 10 SAMME.R True\n",
      "1 5 10 SAMME.R False\n",
      "1 5 10 SAMME True\n",
      "1 5 10 SAMME False\n",
      "1 5 15 SAMME.R True\n",
      "1 5 15 SAMME.R False\n",
      "1 5 15 SAMME True\n",
      "1 5 15 SAMME False\n",
      "1 5 20 SAMME.R True\n",
      "1 5 20 SAMME.R False\n",
      "1 5 20 SAMME True\n",
      "1 5 20 SAMME False\n",
      "1 10 10 SAMME.R True\n",
      "1 10 10 SAMME.R False\n",
      "1 10 10 SAMME True\n",
      "1 10 10 SAMME False\n",
      "1 10 15 SAMME.R True\n",
      "1 10 15 SAMME.R False\n",
      "1 10 15 SAMME True\n",
      "1 10 15 SAMME False\n",
      "1 10 20 SAMME.R True\n",
      "1 10 20 SAMME.R False\n",
      "1 10 20 SAMME True\n",
      "1 10 20 SAMME False\n",
      "2 4 10 SAMME.R True\n",
      "2 4 10 SAMME.R False\n",
      "2 4 10 SAMME True\n",
      "2 4 10 SAMME False\n",
      "2 4 15 SAMME.R True\n",
      "2 4 15 SAMME.R False\n",
      "2 4 15 SAMME True\n",
      "2 4 15 SAMME False\n",
      "2 4 20 SAMME.R True\n",
      "2 4 20 SAMME.R False\n",
      "2 4 20 SAMME True\n",
      "2 4 20 SAMME False\n",
      "2 5 10 SAMME.R True\n",
      "2 5 10 SAMME.R False\n",
      "2 5 10 SAMME True\n",
      "2 5 10 SAMME False\n",
      "2 5 15 SAMME.R True\n",
      "2 5 15 SAMME.R False\n",
      "2 5 15 SAMME True\n",
      "2 5 15 SAMME False\n",
      "2 5 20 SAMME.R True\n",
      "2 5 20 SAMME.R False\n",
      "2 5 20 SAMME True\n",
      "2 5 20 SAMME False\n",
      "2 10 10 SAMME.R True\n",
      "2 10 10 SAMME.R False\n",
      "2 10 10 SAMME True\n",
      "2 10 10 SAMME False\n",
      "2 10 15 SAMME.R True\n",
      "2 10 15 SAMME.R False\n",
      "2 10 15 SAMME True\n",
      "2 10 15 SAMME False\n",
      "2 10 20 SAMME.R True\n",
      "2 10 20 SAMME.R False\n",
      "2 10 20 SAMME True\n",
      "2 10 20 SAMME False\n"
     ]
    }
   ],
   "source": [
    "max_obj_score = 0\n",
    "candidates = []\n",
    "\n",
    "max_depth = [1,2]\n",
    "min_samples_leaf = [4, 5, 10]\n",
    "min_samples_split= [10,15,20]\n",
    "algo = [\"SAMME.R\",\"SAMME\",]\n",
    "\n",
    "for md in max_depth:\n",
    "    for msl in min_samples_leaf:\n",
    "        for mss in min_samples_split:\n",
    "            for a in algo:\n",
    "                for up in [True, False]:\n",
    "                    print(md,msl,mss,a,up)\n",
    "                    report = BinaryClassificationAverageReport(TARGET_NAMES)\n",
    "                    dt = DecisionTreeClassifier(max_depth=md, min_samples_leaf=msl, min_samples_split=mss )\n",
    "                    bdt = AdaBoostClassifier(dt, algorithm=a, n_estimators=500, learning_rate=0.3, random_state= SEED)\n",
    "                    obj_score = cross_valid_process(stratified_folder, X, Y, bdt, report, mode=\"obj\", up=up)\n",
    "                    if obj_score >= max_obj_score:\n",
    "                        candidates.append((md, msl,mss, a, up, obj_score))\n",
    "                        max_obj_score = obj_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4, 10, 'SAMME.R', True, 0.6401323714324441),\n",
       " (1, 4, 15, 'SAMME.R', True, 0.6401323714324441),\n",
       " (1, 4, 20, 'SAMME.R', True, 0.6401323714324441),\n",
       " (1, 10, 10, 'SAMME.R', True, 0.6519454772801614),\n",
       " (1, 10, 15, 'SAMME.R', True, 0.6519454772801614),\n",
       " (1, 10, 20, 'SAMME.R', True, 0.6519454772801614),\n",
       " (2, 4, 10, 'SAMME.R', True, 0.6888876072665755),\n",
       " (2, 5, 15, 'SAMME.R', True, 0.7020063671883592),\n",
       " (2, 10, 10, 'SAMME.R', True, 0.7101335865225722),\n",
       " (2, 10, 15, 'SAMME.R', True, 0.7101335865225722),\n",
       " (2, 10, 20, 'SAMME.R', True, 0.7101335865225722)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness and Performance Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "\n",
      "Below number are the average of 10 fold.\n",
      "\n",
      "bad\n",
      "             precision:    58.41%\n",
      "                recall:    57.00%\n",
      "                    F1:    57.00%\n",
      "good\n",
      "             precision:    82.00%\n",
      "                recall:    82.43%\n",
      "                    F1:    82.05%\n",
      "---------------------------------\n",
      "             weight_F1:    74.53%\n",
      "                   acc:    74.80%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = 1\n",
    "msl = 4\n",
    "mss = 10\n",
    "\n",
    "a = \"SAMME.R\"\n",
    "\n",
    "report = BinaryClassificationAverageReport(TARGET_NAMES)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=md, min_samples_leaf=msl, min_samples_split=mss)\n",
    "bdt = AdaBoostClassifier(dt, algorithm=a, n_estimators=500, learning_rate=0.3, random_state= SEED)\n",
    "\n",
    "cross_valid_process(stratified_folder, X, Y, bdt, report, \"report\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=4,\n",
       "                                                         min_samples_split=10,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.3, n_estimators=500, random_state=5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upsampling(X,Y):\n",
    "    pos = []\n",
    "    for i, t in enumerate(Y):\n",
    "        if t == 0: pos.append(i)\n",
    "    X_new = np.append(X, X[pos], axis=0)\n",
    "    Y_new = np.append(Y, Y[pos], axis=0)\n",
    "    idxs = [i for i in range(len(Y_new))]\n",
    "    idxs = shuffle(idxs, random_state=3)\n",
    "    return X_new[idxs], Y_new[idxs]\n",
    "\n",
    "X_new, Y_new = upsampling(X,Y)\n",
    "\n",
    "md = 1\n",
    "msl = 4\n",
    "mss = 10\n",
    "\n",
    "a = \"SAMME.R\"\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=md, min_samples_leaf=msl, min_samples_split=mss)\n",
    "final_bdt = AdaBoostClassifier(dt, algorithm=a, n_estimators=500, learning_rate=0.3, random_state= SEED)\n",
    "\n",
    "final_bdt.fit(X_new, Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_name = 'best_mdoel.pickle'\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    pickle.dump(final_bdt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
